{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/ubuntu/FedEM/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import General Libraries\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import copy\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import FedEM based Libraries\n",
    "from utils.utils import *\n",
    "from utils.constants import *\n",
    "from utils.args import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from run_experiment import *\n",
    "from models import *\n",
    "\n",
    "# Import Transfer Attack\n",
    "from transfer_attacks.Personalized_NN import *\n",
    "from transfer_attacks.Params import *\n",
    "from transfer_attacks.Transferer import *\n",
    "from transfer_attacks.Args import *\n",
    "\n",
    "from transfer_attacks.TA_utils import *\n",
    "from transfer_attacks.Boundary_Transferer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually set argument parameters\n",
    "args_ = Args()\n",
    "args_.experiment = \"cifar10\"\n",
    "args_.method = \"FedEM_adv\"\n",
    "args_.decentralized = False\n",
    "args_.sampling_rate = 1.0\n",
    "args_.input_dimension = None\n",
    "args_.output_dimension = None\n",
    "args_.n_learners= 3\n",
    "args_.n_rounds = 10\n",
    "args_.bz = 128\n",
    "args_.local_steps = 1\n",
    "args_.lr_lambda = 0\n",
    "args_.lr =0.03\n",
    "args_.lr_scheduler = 'multi_step'\n",
    "args_.log_freq = 10\n",
    "args_.device = 'cuda'\n",
    "args_.optimizer = 'sgd'\n",
    "args_.mu = 0\n",
    "args_.communication_probability = 0.1\n",
    "args_.q = 1\n",
    "args_.locally_tune_clients = False\n",
    "args_.seed = 1234\n",
    "args_.verbose = 1\n",
    "args_.save_path = 'weights/cifar/22_01_09_fedavg_n80_benign/'\n",
    "args_.validation = False\n",
    "args_.num_user = 40\n",
    "\n",
    "# Generate the dummy values here\n",
    "aggregator, clients = dummy_aggregator(args_, num_user=args_.num_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Validation Data across all clients as test\n",
    "data_x = []\n",
    "data_y = []\n",
    "\n",
    "for i in range(len(clients)):\n",
    "    daniloader = clients[i].val_iterator\n",
    "    for (x,y,idx) in daniloader.dataset:\n",
    "        data_x.append(x)\n",
    "        data_y.append(y)\n",
    "\n",
    "data_x = torch.stack(data_x)\n",
    "data_y = torch.stack(data_y)\n",
    "\n",
    "# Create dataloader from validation dataset that allows for diverse batch size\n",
    "dataloader = Custom_Dataloader(data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_names = ['weights/neurips/cifar/client_count/fedem_adv_new2/c5/',\n",
    "             'weights/neurips/cifar/client_count/fedem_adv_new2/c10/',\n",
    "             'weights/neurips/cifar/client_count/fedem_adv_new2/c20/',\n",
    "             'weights/neurips/cifar/client_count/fedem_adv_new2/c30/',\n",
    "             'weights/neurips/cifar/client_count/fedem_adv_new2/c40/']\n",
    "\n",
    "exp_names = ['weights/neurips/cifar/client_count/fedavg_adv_new2/c5/',\n",
    "             'weights/neurips/cifar/client_count/fedavg_adv_new2/c10/',\n",
    "             'weights/neurips/cifar/client_count/fedavg_adv_new2/c20/',\n",
    "             'weights/neurips/cifar/client_count/fedavg_adv_new2/c30/',\n",
    "             'weights/neurips/cifar/client_count/fedavg_adv_new2/c40/']\n",
    "\n",
    "\n",
    "train_item = 'train_client_weights.npy'\n",
    "\n",
    "cc = [5,10,20,30,40]\n",
    "# cc = [50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inter Boundary Distance Metric\n",
    "custom_batch_size = 500\n",
    "\n",
    "exp_logs = {}\n",
    "num_exp = len(exp_names)\n",
    "\n",
    "for j in range(num_exp):\n",
    "    \n",
    "    aggregator, clients = dummy_aggregator(args_, num_user=cc[j])\n",
    "    num_victims = cc[j]\n",
    "    \n",
    "    # Set Up Dictionaries -- list holds the adversary idx\n",
    "\n",
    "\n",
    "    logs_adv = []\n",
    "\n",
    "    for i in range(num_victims):\n",
    "        adv_dict = {}\n",
    "        adv_dict['orig_acc_transfers'] = None\n",
    "        adv_dict['orig_similarities'] = None\n",
    "        adv_dict['adv_acc_transfers'] = None\n",
    "        adv_dict['adv_similarities_target'] = None\n",
    "        adv_dict['adv_similarities_untarget'] = None\n",
    "        adv_dict['adv_target'] = None\n",
    "        adv_dict['adv_miss'] = None\n",
    "        adv_dict['metric_alignment'] = None\n",
    "        adv_dict['ib_distance_legit'] = None\n",
    "        adv_dict['ib_distance_adv'] = None\n",
    "\n",
    "        logs_adv += [adv_dict]\n",
    "\n",
    "    exp_logs[j] = copy.deepcopy(logs_adv)\n",
    "\n",
    "    \n",
    "    \n",
    "    print('processing file', exp_names[j], '...')\n",
    "    \n",
    "    # Change name if need be\n",
    "    args_.save_path = exp_names[j]\n",
    "\n",
    "    # Import weights for aggregator\n",
    "    aggregator.load_state(args_.save_path)\n",
    "\n",
    "    # This is where the models are stored -- one for each mixture --> learner.model for nn\n",
    "    hypotheses = aggregator.global_learners_ensemble.learners\n",
    "\n",
    "    # obtain the state dict for each of the weights \n",
    "    weights_h = []\n",
    "\n",
    "    for h in hypotheses:\n",
    "        weights_h += [h.model.state_dict()]\n",
    "        \n",
    "    weight_name = args_.save_path + train_item\n",
    "    weights = np.load(weight_name)\n",
    "    np.set_printoptions(formatter={'float': lambda x: \"{0:0.2f}\".format(x)})\n",
    "\n",
    "    # Set model weights\n",
    "    model_weights = []\n",
    "    num_models = num_victims\n",
    "\n",
    "    for i in range(num_models):\n",
    "        model_weights += [weights[i]]\n",
    "\n",
    "\n",
    "    # Generate the weights to test on as linear combinations of the model_weights\n",
    "    models_test = []\n",
    "\n",
    "    for (w0,w1,w2) in model_weights:\n",
    "        # first make the model with empty weights\n",
    "        new_model = copy.deepcopy(hypotheses[0].model)\n",
    "        new_model.eval()\n",
    "        new_weight_dict = copy.deepcopy(weights_h[0])\n",
    "        for key in weights_h[0]:\n",
    "            new_weight_dict[key] = w0*weights_h[0][key]  + w1*weights_h[1][key] +w2*weights_h[2][key] \n",
    "        new_model.load_state_dict(new_weight_dict)\n",
    "        models_test += [new_model]\n",
    "    \n",
    "\n",
    "    victim_idxs = range(num_victims)\n",
    "\n",
    "    for adv_idx in victim_idxs:\n",
    "        print(\"\\t Adv idx:\", adv_idx)\n",
    "        # Perform Attacks\n",
    "        dataloader = load_client_data(clients = clients, c_id = adv_idx, mode = 'test') # or test/train\n",
    "        batch_size = min(custom_batch_size, dataloader.y_data.shape[0])\n",
    "        \n",
    "        t1 = Transferer(models_list=models_test, dataloader=dataloader)\n",
    "        t1.generate_victims(victim_idxs)\n",
    "        \n",
    "        t1.atk_params = PGD_Params()\n",
    "        t1.atk_params.set_params(batch_size=batch_size, iteration = 10,\n",
    "                       target = 3, x_val_min = torch.min(data_x), x_val_max = torch.max(data_x),\n",
    "                       step_size = 0.01, step_norm = \"inf\", eps = 4, eps_norm = 2)\n",
    "\n",
    "        t1.generate_advNN(adv_idx)\n",
    "        t1.generate_xadv(atk_type = \"pgd\")\n",
    "        t1.send_to_victims(victim_idxs)\n",
    "        # t1.check_empirical_metrics(orig_flag = True)\n",
    "\n",
    "        # Log Performance\n",
    "        exp_logs[j][adv_idx]['orig_acc_transfers'] = copy.deepcopy(t1.orig_acc_transfers)\n",
    "        exp_logs[j][adv_idx]['orig_similarities'] = copy.deepcopy(t1.orig_similarities)\n",
    "        exp_logs[j][adv_idx]['adv_acc_transfers'] = copy.deepcopy(t1.adv_acc_transfers)\n",
    "        exp_logs[j][adv_idx]['adv_similarities_target'] = copy.deepcopy(t1.adv_similarities)        \n",
    "        exp_logs[j][adv_idx]['adv_target'] = copy.deepcopy(t1.adv_target_hit)\n",
    "\n",
    "        # Miss attack\n",
    "        t1.atk_params.set_params(batch_size=batch_size, iteration = 10,\n",
    "                       target = -1, x_val_min = torch.min(data_x), x_val_max = torch.max(data_x),\n",
    "                       step_size = 0.01, step_norm = \"inf\", eps = 4, eps_norm = 2)\n",
    "        t1.generate_xadv(atk_type = \"pgd\")\n",
    "        t1.send_to_victims(victim_idxs)\n",
    "        exp_logs[j][adv_idx]['adv_miss'] = copy.deepcopy(t1.adv_acc_transfers)\n",
    "        exp_logs[j][adv_idx]['adv_similarities_untarget'] = copy.deepcopy(t1.adv_similarities)\n",
    "\n",
    "\n",
    "    del models_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organizing and plotting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['orig_acc_transfers','orig_similarities','adv_acc_transfers','adv_similarities_target',\n",
    "           'adv_similarities_untarget','adv_target','adv_miss'] #,'metric_alignment']\n",
    "\n",
    "\n",
    "orig_acc = []\n",
    "orig_sim = []\n",
    "adv_acc = []\n",
    "adv_sim_target = []\n",
    "adv_sim_untarget = []\n",
    "adv_target = []\n",
    "adv_miss = []\n",
    "\n",
    "for i in range(len(exp_names)):\n",
    "    victim_idxs = range(cc[i])\n",
    "    \n",
    "    orig_acc += [np.zeros([len(victim_idxs),len(victim_idxs)])]\n",
    "    orig_sim += [np.zeros([len(victim_idxs),len(victim_idxs)])]\n",
    "    adv_acc += [np.zeros([len(victim_idxs),len(victim_idxs)]) ]\n",
    "    adv_sim_target += [np.zeros([len(victim_idxs),len(victim_idxs)]) ]\n",
    "    adv_sim_untarget += [np.zeros([len(victim_idxs),len(victim_idxs)]) ]\n",
    "    adv_target += [np.zeros([len(victim_idxs),len(victim_idxs)])]\n",
    "    adv_miss += [np.zeros([len(victim_idxs),len(victim_idxs)]) ]\n",
    "    \n",
    "    for adv_idx in range(len(victim_idxs)):\n",
    "        for victim in range(len(victim_idxs)):\n",
    "            orig_acc[i][adv_idx,victim] = exp_logs[i][victim_idxs[adv_idx]][metrics[0]][victim_idxs[victim]].data.tolist()\n",
    "            orig_sim[i][adv_idx,victim] = exp_logs[i][victim_idxs[adv_idx]][metrics[1]][victim_idxs[victim]].data.tolist()\n",
    "            adv_acc[i][adv_idx,victim] = exp_logs[i][victim_idxs[adv_idx]][metrics[2]][victim_idxs[victim]].data.tolist()\n",
    "            adv_sim_target[i][adv_idx,victim] = exp_logs[i][victim_idxs[adv_idx]][metrics[3]][victim_idxs[victim]].data.tolist()\n",
    "            adv_sim_untarget[i][adv_idx,victim] = exp_logs[i][victim_idxs[adv_idx]][metrics[4]][victim_idxs[victim]].data.tolist()\n",
    "            adv_target[i][adv_idx,victim] = exp_logs[i][victim_idxs[adv_idx]][metrics[5]][victim_idxs[victim]].data.tolist()\n",
    "            adv_miss[i][adv_idx,victim] = exp_logs[i][victim_idxs[adv_idx]][metrics[6]][victim_idxs[victim]].data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit desired data\n",
    "x = [5,10,20,30,40]\n",
    "# Acc\n",
    "y_acc = []\n",
    "y_robust = []\n",
    "y_target = []\n",
    "\n",
    "y_acc_std = []\n",
    "y_robust_std = []\n",
    "y_target_std = []\n",
    "\n",
    "for i in range(len(exp_names)):\n",
    "    y_acc += [np.mean(np.diagonal(orig_acc[i]))]\n",
    "    y_robust += [avg_nondiag(adv_miss[i])]\n",
    "    y_target += [avg_nondiag(adv_target[i])]\n",
    "    \n",
    "    y_acc_std += [np.std(orig_acc[i])]\n",
    "    y_robust_std += [np.std(adv_miss[i])]\n",
    "    y_target_std += [np.std(adv_target[i])]\n",
    "    \n",
    "print('y_acc', y_acc)\n",
    "print('y_robust', y_robust)\n",
    "print('y_target', y_target)\n",
    "\n",
    "print('y_acc_std', y_acc_std)\n",
    "print('y_robust_std', y_robust_std)\n",
    "print('y_target_std', y_target_std)\n",
    "\n",
    "\n",
    "y = [y_acc, y_robust, y_target]\n",
    "y_std = [y_acc_std, y_robust_std, y_target_std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [5,10,20,30,40]\n",
    "\n",
    "# FedEM - old 0.03 lr\n",
    "y_acc_em = [0.6450916767120362, 0.667163860797882, 0.7196145206689835, 0.720850157737732, 0.7528059154748916]\n",
    "y_robust_em = [0.3376933032646775, 0.3707165161354674, 0.3706623485507934, 0.367587899275381, 0.3754598111081391]\n",
    "y_target_em = [0.16837104493752122, 0.2121713483085235, 0.2247929244939434, 0.22865982262374854, 0.23709892451357192]\n",
    "\n",
    "# y_acc_em = [0.5819306254386902, 0.6657283306121826, 0.7431143581867218, 0.7719452460606893, 0.7966105282306671]\n",
    "y_robust_em =  [0.35415015784092246, 0.39264643508940933, 0.3994966171436796, 0.4055137311729292, 0.40981366842006073]\n",
    "y_target_em =  [0.13879860425367951, 0.20127729040880998, 0.22036700596248632, 0.21891754053789994, 0.22881760303444493]\n",
    "\n",
    "y_acc_em_std = [0.07715692702770657, 0.134821769318538, 0.14979020426055112, 0.1725262015915895, 0.13955413658865676]\n",
    "y_robust_em_std = [0.16842491698974255, 0.14584983949968125, 0.11692460946142592, 0.168527260968774, 0.11356905465607631]\n",
    "y_target_em_std = [0.22282912442323527, 0.15064613492510565, 0.1524870111640661, 0.17622101766056286, 0.13216387077689332]\n",
    "\n",
    "# FedAvg - 0.03 lr \n",
    "y_acc_av = [0.6294841051101685, 0.6529397249221802, 0.6934066414833069, 0.7202447414398193, 0.7370424076914788]\n",
    "y_robust_av = [0.015053732320666313, 0.029244875721633434, 0.030035770777612925, 0.042258040669063725, 0.051227377727627754]\n",
    "y_target_av = [0.7822269797325134, 0.7007585525512695, 0.677129927277565, 0.6396990636984508, 0.6634831979870797]\n",
    "\n",
    "# y_acc [0.6941302180290222, 0.6607008337974548, 0.7449679762125015, 0.7697312970956166, 0.7814813435077668]\n",
    "y_robust_av =  [0.08143896963447332, 0.13016922809183598, 0.11168823037296534, 0.1819001279771328, 0.1540095795877278]\n",
    "# y_target [0.6277596950531006, 0.6878000915050506, 0.6856336414813995, 0.6380018383264542, 0.6570352114737034]\n",
    "\n",
    "y_acc_av_std = [0.04031361514283589, 0.05854536878793412, 0.06402912990515197, 0.05242600881256371, 0.04878897240792139]\n",
    "y_robust_av_std = [0.01101476494045161, 0.017256414589478505, 0.015363092648985437, 0.0250374195485548, 0.027936583203989007]\n",
    "y_target_av_std = [0.03636901079467588, 0.025679957085663212, 0.06059209049248106, 0.0843089274817277, 0.08538553261566446]\n",
    "\n",
    "y1 = [y_acc_em, y_robust_em, y_target_em]\n",
    "y1_std = [y_acc_em_std, y_robust_em_std, y_target_em_std]\n",
    "y2 = [y_acc_av, np.multiply(y_robust_av,1), y_target_av]\n",
    "y2_std = [y_acc_av_std, np.multiply(y_robust_av_std,1), y_target_av_std]\n",
    "\n",
    "\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 14.5}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "\n",
    "names1 = ['pFedDef Test Acc.', 'pFedDef Adv. Acc.']\n",
    "names2 = ['FAT Test Acc.', 'FAT Adv. Acc.']\n",
    "colors = ['b','r']\n",
    "types = ['-', '--']\n",
    "\n",
    "plt.figure(figsize=(6, 4), dpi=300)\n",
    "\n",
    "offset = 0.1\n",
    "\n",
    "\n",
    "for i in range(len(names1)):\n",
    "    plt.errorbar(np.array(x[:-1]) - offset,y1[i][:-1], y1_std[i][:-1], label= names1[i], linestyle = types[i], color = colors[0])\n",
    "for i in range(len(names2)):\n",
    "    plt.errorbar(np.array(x[:-1]) + offset ,y2[i][:-1], y2_std[i][:-1], label= names2[i], linestyle = types[i], color = colors[1])\n",
    "    \n",
    "plt.legend(frameon=True,loc = (0.27, 0.52), prop={'size': 11})\n",
    "plt.xlim(3, 33);\n",
    "plt.ylim(0.0, 0.8);\n",
    "plt.xlabel('Number of FL Clients')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"CIFAR-10 FL Client Count\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FedEM_env",
   "language": "python",
   "name": "fedem_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
